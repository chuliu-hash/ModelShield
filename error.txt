─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮
│ /usr/local/anaconda3/.conda/envs/modelshield/lib/python3.9/site-packages/transformers/tokenizati │
│ on_utils_base.py:717 in convert_to_tensors                                                       │
│                                                                                                  │
│    714 │   │   │   │   │   value = [value]                                                       │
│    715 │   │   │   │                                                                             │
│    716 │   │   │   │   if not is_tensor(value):                                                  │
│ ❱  717 │   │   │   │   │   tensor = as_tensor(value)                                             │
│    718 │   │   │   │   │                                                                         │
│    719 │   │   │   │   │   # Removing this for now in favor of controlling the shape with `prep  │
│    720 │   │   │   │   │   # # at-least2d                                                        │
╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
ValueError: too many dimensions 'str'

The above exception was the direct cause of the following exception:

╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮
│ /home/xuzhen/ModelShield-master/Imitation_Model_training/train/finetune_imitation_model_my.py:24 │
│ 8 in <module>                                                                                    │
│                                                                                                  │
│   245 │   parser.add_argument("--local_rank", type=int)                                          │
│   246 │   # parser.add_argument("--action", type=str)                                            │
│   247 │   args = parser.parse_args()                                                             │
│ ❱ 248 │   fire.Fire(train)                                                                       │
│   249                                                                                            │
│                                                                                                  │
│ /usr/local/anaconda3/.conda/envs/modelshield/lib/python3.9/site-packages/fire/core.py:141 in     │
│ Fire                                                                                             │
│                                                                                                  │
│   138 │   context.update(caller_globals)                                                         │
│   139 │   context.update(caller_locals)                                                          │
│   140                                                                                            │
│ ❱ 141   component_trace = _Fire(component, args, parsed_flag_args, context, name)                │
│   142                                                                                            │
│   143   if component_trace.HasError():                                                           │
│   144 │   _DisplayError(component_trace)                                                         │
│                                                                                                  │
│ /usr/local/anaconda3/.conda/envs/modelshield/lib/python3.9/site-packages/fire/core.py:475 in     │
│ _Fire                                                                                            │
│                                                                                                  │
│   472 │     is_class = inspect.isclass(component)                                                │
│   473 │                                                                                          │
│   474 │     try:                                                                                 │
│ ❱ 475 │   │   component, remaining_args = _CallAndUpdateTrace(                                   │
│   476 │   │   │   component,                                                                     │
│   477 │   │   │   remaining_args,                                                                │
│   478 │   │   │   component_trace,                                                               │
│                                                                                                  │
│ /usr/local/anaconda3/.conda/envs/modelshield/lib/python3.9/site-packages/fire/core.py:691 in     │
│ _CallAndUpdateTrace                                                                              │
│                                                                                                  │
│   688 │   loop = asyncio.get_event_loop()                                                        │
│   689 │   component = loop.run_until_complete(fn(*varargs, **kwargs))                            │
│   690   else:                                                                                    │
│ ❱ 691 │   component = fn(*varargs, **kwargs)                                                     │
│   692                                                                                            │
│   693   if treatment == 'class':                                                                 │
│   694 │   action = trace.INSTANTIATED_CLASS                                                      │
│                                                                                                  │
│ /home/xuzhen/ModelShield-master/Imitation_Model_training/train/finetune_imitation_model_my.py:22 │
│ 4 in train                                                                                       │
│                                                                                                  │
│   221 │   if torch.__version__ >= "2" and sys.platform != "win32":                               │
│   222 │   │   model = torch.compile(model)                                                       │
│   223 │   print("trainer.train")                                                                 │
│ ❱ 224 │   trainer.train(resume_from_checkpoint = args.resume_from_checkpoint)                    │
│   225 │   logger.info("Save checkpointing...")                                                   │
│   226 │                                                                                          │
│   227 │   model.save_pretrained(output_dir)                                                      │
│                                                                                                  │
│ /usr/local/anaconda3/.conda/envs/modelshield/lib/python3.9/site-packages/transformers/trainer.py │
│ :1662 in train                                                                                   │
│                                                                                                  │
│   1659 │   │   inner_training_loop = find_executable_batch_size(                                 │
│   1660 │   │   │   self._inner_training_loop, self._train_batch_size, args.auto_find_batch_size  │
│   1661 │   │   )                                                                                 │
│ ❱ 1662 │   │   return inner_training_loop(                                                       │
│   1663 │   │   │   args=args,                                                                    │
│   1664 │   │   │   resume_from_checkpoint=resume_from_checkpoint,                                │
│   1665 │   │   │   trial=trial,                                                                  │
│                                                                                                  │
│ /usr/local/anaconda3/.conda/envs/modelshield/lib/python3.9/site-packages/transformers/trainer.py │
│ :1899 in _inner_training_loop                                                                    │
│                                                                                                  │
│   1896 │   │   │   │   rng_to_sync = True                                                        │
│   1897 │   │   │                                                                                 │
│   1898 │   │   │   step = -1                                                                     │
│ ❱ 1899 │   │   │   for step, inputs in enumerate(epoch_iterator):                                │
│   1900 │   │   │   │   total_batched_samples += 1                                                │
│   1901 │   │   │   │   if rng_to_sync:                                                           │
│   1902 │   │   │   │   │   self._load_rng_state(resume_from_checkpoint)                          │
│                                                                                                  │
│ /usr/local/anaconda3/.conda/envs/modelshield/lib/python3.9/site-packages/torch/utils/data/datalo │
│ ader.py:628 in __next__                                                                          │
│                                                                                                  │
│    625 │   │   │   if self._sampler_iter is None:                                                │
│    626 │   │   │   │   # TODO(https://github.com/pytorch/pytorch/issues/76750)                   │
│    627 │   │   │   │   self._reset()  # type: ignore[call-arg]                                   │
│ ❱  628 │   │   │   data = self._next_data()                                                      │
│    629 │   │   │   self._num_yielded += 1                                                        │
│    630 │   │   │   if self._dataset_kind == _DatasetKind.Iterable and \                          │
│    631 │   │   │   │   │   self._IterableDataset_len_called is not None and \                    │
│                                                                                                  │
│ /usr/local/anaconda3/.conda/envs/modelshield/lib/python3.9/site-packages/torch/utils/data/datalo │
│ ader.py:671 in _next_data                                                                        │
│                                                                                                  │
│    668 │                                                                                         │
│    669 │   def _next_data(self):                                                                 │
│    670 │   │   index = self._next_index()  # may raise StopIteration                             │
│ ❱  671 │   │   data = self._dataset_fetcher.fetch(index)  # may raise StopIteration              │
│    672 │   │   if self._pin_memory:                                                              │
│    673 │   │   │   data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)            │
│    674 │   │   return data                                                                       │
│                                                                                                  │
│ /usr/local/anaconda3/.conda/envs/modelshield/lib/python3.9/site-packages/torch/utils/data/_utils │
│ /fetch.py:61 in fetch                                                                            │
│                                                                                                  │
│   58 │   │   │   │   data = [self.dataset[idx] for idx in possibly_batched_index]                │
│   59 │   │   else:                                                                               │
│   60 │   │   │   data = self.dataset[possibly_batched_index]                                     │
│ ❱ 61 │   │   return self.collate_fn(data)                                                        │
│   62                                                                                             │
│                                                                                                  │
│ /usr/local/anaconda3/.conda/envs/modelshield/lib/python3.9/site-packages/transformers/data/data_ │
│ collator.py:586 in __call__                                                                      │
│                                                                                                  │
│    583 │   │   │   │   else:                                                                     │
│    584 │   │   │   │   │   feature["labels"] = np.concatenate([remainder, feature["labels"]]).a  │
│    585 │   │                                                                                     │
│ ❱  586 │   │   features = self.tokenizer.pad(                                                    │
│    587 │   │   │   features,                                                                     │
│    588 │   │   │   padding=self.padding,                                                         │
│    589 │   │   │   max_length=self.max_length,                                                   │
│                                                                                                  │
│ /usr/local/anaconda3/.conda/envs/modelshield/lib/python3.9/site-packages/transformers/tokenizati │
│ on_utils_base.py:3035 in pad                                                                     │
│                                                                                                  │
│   3032 │   │   │   │   │   batch_outputs[key] = []                                               │
│   3033 │   │   │   │   batch_outputs[key].append(value)                                          │
│   3034 │   │                                                                                     │
│ ❱ 3035 │   │   return BatchEncoding(batch_outputs, tensor_type=return_tensors)                   │
│   3036 │                                                                                         │
│   3037 │   def create_token_type_ids_from_sequences(                                             │
│   3038 │   │   self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None             │
│                                                                                                  │
│ /usr/local/anaconda3/.conda/envs/modelshield/lib/python3.9/site-packages/transformers/tokenizati │
│ on_utils_base.py:210 in __init__                                                                 │
│                                                                                                  │
│    207 │   │                                                                                     │
│    208 │   │   self._n_sequences = n_sequences                                                   │
│    209 │   │                                                                                     │
│ ❱  210 │   │   self.convert_to_tensors(tensor_type=tensor_type, prepend_batch_axis=prepend_batc  │
│    211 │                                                                                         │
│    212 │   @property                                                                             │
│    213 │   def n_sequences(self) -> Optional[int]:                                               │
│                                                                                                  │
│ /usr/local/anaconda3/.conda/envs/modelshield/lib/python3.9/site-packages/transformers/tokenizati │
│ on_utils_base.py:733 in convert_to_tensors                                                       │
│                                                                                                  │
│    730 │   │   │   │   │   │   "Unable to create tensor returning overflowing tokens of differe  │
│    731 │   │   │   │   │   │   "Please see if a fast version of this tokenizer is available to   │
│    732 │   │   │   │   │   ) from e                                                              │
│ ❱  733 │   │   │   │   raise ValueError(                                                         │
│    734 │   │   │   │   │   "Unable to create tensor, you should probably activate truncation an  │
│    735 │   │   │   │   │   " 'padding=True' 'truncation=True' to have batched tensors with the   │
│    736 │   │   │   │   │   f" features (`{key}` in this case) have excessive nesting (inputs ty  │
╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
ValueError: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps 
your features (`sentence` in this case) have excessive nesting (inputs type `list` where type `int` is expected).
  0%|                                                   